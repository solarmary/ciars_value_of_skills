{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy import spatial\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import random\n",
    "from datetime import datetime\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from math import sqrt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import plotly.express as px\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import psycopg2\n",
    "from sklearn.model_selection import KFold\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    connection = psycopg2.connect(user=\"RemoteFA\",\n",
    "                                    database=\"fa\",\n",
    "                                \n",
    "                                    password=\"RFA_127_BT_fandc\",\n",
    "                                    host=\"rc1b-bdye1rzk75u6dgzf.mdb.yandexcloud.net\",\n",
    "                                    port=\"6432\",\n",
    "                                    sslmode = \"allow\")\n",
    "\n",
    "except Exception as error:\n",
    "    print(\"Ошибка при работе с PostgreSQL\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# хуйня\n",
    "#####################################################################\n",
    "########## ДАННЫЕ ######################\n",
    "n_bundle = 102\n",
    "type_data = 'train'\n",
    "batch = 3 \n",
    "\n",
    "def make_good_view(df, list_vac_skills):\n",
    "    columns_to_drop = ['vacancies_type_id', 'is_shift', 'is_distance', 'is_multiple', 'description_hash2', 'is_junior', 'is_senior', 'part']\n",
    "    if 'linked_bundles' in df.columns:\n",
    "        columns_to_drop.append('linked_bundles')\n",
    "\n",
    "    df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "    d_v3_region_bs = pd.read_sql('SELECT index as v3_region_index, new_region_id FROM public.d_v3_region_bs', connection)\n",
    "    d_v3_new_region_id = pd.read_sql('SELECT new_id as new_region_id, region_name as region_name1,country_name FROM public.d_v3_new_region_id', connection)\n",
    "    # добавляем про регион\n",
    "    df = df.merge(d_v3_region_bs).merge(d_v3_new_region_id)\n",
    "    df = df[df.country_name == 'Россия']\n",
    "    df.insert(0, 'region_name', df.region_name1)\n",
    "    df.insert(0, 'region', df.new_region_id)\n",
    "    df = df.drop(['new_region_id', 'region_name1', 'country_name', 'region'], axis=1)\n",
    "    # добавляем год\n",
    "    df['first_pub_date'] = pd.to_datetime(df['first_pub_date'])\n",
    "    df.insert(0, 'year', df['first_pub_date'].dt.year)\n",
    "\n",
    "    df['new_salary'] = None # т.к. в дф в зп только наны\n",
    "    df.rename(columns={'index': 'id'}, inplace=True)\n",
    "    industry_df = pd.read_csv('./ind_groups_2.csv')\n",
    "    df = df.merge(industry_df[['region_name', 'industry_group']], on='region_name', how='left')\n",
    "    df = df[['id','salary_from_rub', 'source_site', 'year', 'new_salary', 'is_vahta', 'experience_id', 'region_name','industry_group','is_parttime']+list(list_vac_skills)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_ans_df(based_path, n_bundle, type_data, batch):\n",
    "    type_dict = {'train':1, 'test':2} # train/test\n",
    "    batch_data = {1:'20230621', 2:'20230725', 3:'20230929'} # какая партия бундлов (по 25 шт)\n",
    "\n",
    "    # базированные\n",
    "    # based_path = './bundles_based_train_0929'\n",
    "    based_list = [i for i in os.listdir(based_path) if 'based_b' in i]\n",
    "    df_based = pd.read_csv(f'{based_path}/based_b_{n_bundle}.csv')\n",
    "\n",
    "    # таблица где айди вакансии и соответствующий айдишник \n",
    "    df2 = pd.read_sql(f'SELECT * FROM public.v3_vac_type_id_{n_bundle}_part_{type_dict[type_data]}_bundles_{batch_data[batch]}', connection)\n",
    "    df2.dropna(inplace=True)\n",
    "    df2['bundle_id'] = df2['bundle_id'].astype('int')\n",
    "\n",
    "\n",
    "    #####################################################################\n",
    "    # сначала для всего сырого датафрейма из бд (пусть это будет df_start) проставляю навыки (1)\n",
    "    df_start = pd.read_sql(f'SELECT * FROM public.v3_vacancies_all_type_id_{n_bundle}_part_{type_dict[type_data]}_{batch_data[batch]}', connection) # будущие финальные\n",
    "    missing_ids = df_start.loc[~df_start['index'].isin(df_based['id']), 'index'].tolist() # айдишники которые есть в start_df (raw data), но нет в based\n",
    "    start_df = df_start[df_start['index'].isin(missing_ids)]\n",
    "\n",
    "\n",
    "    # названия столбцов с навыками из df_based\n",
    "    list_vac_skills = df_based.columns[df_based.columns.tolist().index('is_parttime')+1:]\n",
    "    for col_name in list_vac_skills:\n",
    "        df_start[col_name] = None  \n",
    "\n",
    "\n",
    "    # для данного бундла ключ (цифра айди навыка) - значение (полное название навыка)\n",
    "    dict_temp = [re.search(r'\\((\\d+)_', i).group(1) for i in list_vac_skills]\n",
    "    if len(set(dict_temp)) != len(list_vac_skills):\n",
    "        print('ОПА БЕДЫ')\n",
    "    dict_skills = {int(dict_temp[i]):list_vac_skills[i] for i in range(len(list_vac_skills))}\n",
    "\n",
    "\n",
    "    # проставляем навыки\n",
    "    # т.к. не все навыки из raw есть в based\n",
    "    df2 = df2[df2['bundle_id'].isin(list(dict_skills.keys()))]\n",
    "    df2 = df2[df2['v3_all_index'].isin(df_start['index'].values)]\n",
    "    df_start.set_index('index', inplace=True)\n",
    "    for index, row in df_start.iterrows():\n",
    "        skills_one = df2[df2['v3_all_index']==index]['bundle_id'].values\n",
    "\n",
    "        if skills_one != []:\n",
    "            df_start.loc[index, [dict_skills[col] for col in skills_one]] = 1\n",
    "    df_start.reset_index(inplace=True)\n",
    "\n",
    "    # теперь оставляем только те строки в df_start, в которых есть навыки, но в зп нан\n",
    "    ans_df = df_start[(~df_start[list_vac_skills].isna().all(axis=1)) & (df_start['salary_from_rub'].isna())]\n",
    "    ans_df = make_good_view(ans_df, list_vac_skills)\n",
    "    return ans_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bundles1 = [16, 27, 31, 33, 49, 52, 54, 58, 61, 69, 74, 91, 116, 119, 128, 134, 283, 336, 663, 706, 767, 783, 833, 836, 919]\n",
    "bundles2 = [43, 23, 84, 85, 87, 124, 357, 561, 693, 712, 742, 765, 811, 812, 852, 853, 856, 873, 876, 888, 898, 917, 921, 954, 992]\n",
    "# bundles3 = [2, 35, 40, 86, 102, 111, 320, 324, 325, 326, 337, 698, 720, 734, 760, 804, 829, 850, 904, 941, 982, 994, 996, 997, 998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 (433, 73)\n",
      "43 (14620, 171)\n",
      "84 (715, 122)\n",
      "85 (19091, 372)\n",
      "87 (490, 134)\n",
      "124 (31, 64)\n",
      "357 (25, 57)\n",
      "561 (2, 22)\n",
      "693 (67, 31)\n",
      "712 (121, 34)\n",
      "742 (118, 25)\n",
      "765 (968, 94)\n",
      "811 (172, 48)\n",
      "812 (262, 42)\n",
      "852 (0, 20)\n",
      "853 (76, 71)\n",
      "856 (127, 67)\n",
      "873 (33, 40)\n",
      "876 (10, 19)\n",
      "888 (1955, 76)\n",
      "898 (1184, 49)\n",
      "917 (1, 28)\n",
      "921 (92, 50)\n",
      "954 (206, 34)\n",
      "992 (2099, 127)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "based_path = './bundles_based_test_0725' # папка где лежат based таблицы\n",
    "type_data = 'test' \n",
    "batch = 2 # какая группа навыков? (1-ые 25, 2-ые, 3-и)\n",
    "\n",
    "bundles2 = [23, 43, 84, 85, 87, 124, 357, 561, 693, 712, 742, 765, 811, 812, 852, 853, 856, 873, 876, 888, 898, 917, 921, 954, 992]\n",
    "\n",
    "for n_bundle in bundles2:\n",
    "    # постоянно вылетало, поэтому сюда добавила\n",
    "    try:\n",
    "        connection = psycopg2.connect(user=\"RemoteFA\",\n",
    "                                        database=\"fa\",\n",
    "                                    \n",
    "                                        password=\"RFA_127_BT_fandc\",\n",
    "                                        host=\"rc1b-bdye1rzk75u6dgzf.mdb.yandexcloud.net\",\n",
    "                                        port=\"6432\",\n",
    "                                        sslmode = \"allow\")\n",
    "\n",
    "    except Exception as error:\n",
    "        print(\"Ошибка при работе с PostgreSQL\", error)\n",
    "\n",
    "    \n",
    "    temp_df = make_ans_df(based_path, n_bundle, type_data, batch)\n",
    "    temp_df.to_csv(f'./send/{batch}/{type_data}/{n_bundle}.csv', encoding='utf-8-sig', index = False)\n",
    "    print(n_bundle, temp_df.shape)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
